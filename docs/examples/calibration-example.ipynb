{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter, AutoMinorLocator\n",
    "from pathlib import Path\n",
    "from scipy.stats import bootstrap\n",
    "from radiocalibrationtoolkit import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some ad-hoc plotting functions\n",
    "\n",
    "def statistic_without_nans(col, func):\n",
    "    if func is not None:\n",
    "        return func(col.dropna())\n",
    "    else:\n",
    "        raise ValueError(\"Invalid function argument.\")\n",
    "    \n",
    "def calculate_and_plot_with_true(df_true_sim_file_path, power_rec_DF):\n",
    "    power_sim_true_DF = pd.read_csv(df_true_sim_file_path[0], index_col=0)\n",
    "    power_sim_true_DF.columns = power_sim_true_DF.columns.astype(float)\n",
    "\n",
    "    frequencies_MHz = power_sim_true_DF.columns.values\n",
    "    slopes = []\n",
    "    intercepts = []\n",
    "    for i, freq in enumerate(power_sim_true_DF.columns):\n",
    "        x_arr = power_sim_true_DF.loc[:, freq].values\n",
    "        y_arr = power_rec_DF.loc[:, freq].values\n",
    "        intercept, slope = robust_regression(x_arr, y_arr)\n",
    "        intercepts.append(intercept)\n",
    "        slopes.append(slope)\n",
    "\n",
    "    intercepts = np.asarray(intercepts) ** (1 / 2)\n",
    "    slopes = np.asarray(slopes) ** (1 / 2)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    fig.suptitle(Path(df_true_sim_file_path[0]).stem)\n",
    "    ax[0].plot(frequencies_MHz, (slopes), marker=\"o\", linestyle=\"\")\n",
    "    median = np.median(slopes[~np.isnan(slopes)])\n",
    "    ax[0].axes.axhline(median, label=\"median={:.2f}\".format(median), color=\"red\")\n",
    "    ax[0].set_ylim(0.8, 1.2)\n",
    "    ax[0].set_xlabel(\"frequency [MHz]\")\n",
    "    ax[0].set_ylabel(\"voltage \\ncalibration parameter\")\n",
    "    ax[0].xaxis.set_major_locator(MultipleLocator(10))\n",
    "    ax[0].legend()\n",
    "    ax[1].bar(frequencies_MHz, intercepts, width=1)\n",
    "    # ax[1].set_ylim(0, 5)\n",
    "    ax[1].set_xlabel(\"frequency [MHz]\")\n",
    "    ax[1].set_ylabel(\"voltage \\nnoise offset \")\n",
    "    ax[1].xaxis.set_major_locator(MultipleLocator(10))\n",
    "\n",
    "    fig.subplots_adjust(wspace=0.3, bottom=0.2)\n",
    "\n",
    "\n",
    "def get_slope_and_intercepts_dfs(concatenated_df, power_rec_DF):\n",
    "    slopes_dict = {}\n",
    "    intercepts_dict = {}\n",
    "\n",
    "    for key in concatenated_df.index.levels[0]:\n",
    "        power_sim_DF = concatenated_df.xs(key)\n",
    "        frequencies_MHz = power_sim_DF.columns.values\n",
    "\n",
    "        slopes = []\n",
    "        intercepts = []\n",
    "        for i, freq in enumerate(power_sim_DF.columns):\n",
    "            x_arr = power_sim_DF.loc[:, freq].values\n",
    "            y_arr = power_rec_DF.loc[:, freq].values\n",
    "\n",
    "            intercept, slope = robust_regression(x_arr, y_arr)\n",
    "            intercepts.append(intercept)\n",
    "            slopes.append(slope)\n",
    "\n",
    "        slopes_dict[key] = np.asarray(slopes) ** (1 / 2)\n",
    "        intercepts_dict[key] = np.asarray(intercepts) ** (1 / 2)\n",
    "\n",
    "    slopes_DF = pd.DataFrame(slopes_dict).T\n",
    "    slopes_DF.columns = power_sim_DF.columns\n",
    "    intercepts_DF = pd.DataFrame(intercepts_dict).T\n",
    "    intercepts_DF.columns = power_sim_DF.columns\n",
    "\n",
    "    return slopes_DF, intercepts_DF\n",
    "\n",
    "\n",
    "def bounds_from_slope_DF(slopes_DF, stat_func):\n",
    "    bounds = []\n",
    "    for col in slopes_DF.columns:\n",
    "        boot_res = bootstrap(\n",
    "            (slopes_DF.loc[:, col].values,),\n",
    "            stat_func,\n",
    "            n_resamples=1000,\n",
    "            confidence_level=0.68,\n",
    "            method=\"BCa\",\n",
    "        )\n",
    "        bounds.append(\n",
    "            (boot_res.confidence_interval.low, boot_res.confidence_interval.high)\n",
    "        )\n",
    "    bounds = np.asarray(bounds).T\n",
    "    freq_dependent_slopes = slopes_DF.apply(statistic_without_nans, args=(stat_func,))\n",
    "    return freq_dependent_slopes, bounds\n",
    "\n",
    "\n",
    "def plot_results_with_CI(slopes_DF, intercepts_DF, title=\"\", labels=None):\n",
    "    # calculate\n",
    "    stat_func = np.mean\n",
    "    stat = \"mean\"\n",
    "\n",
    "    freq_dependent_slopes, bounds = bounds_from_slope_DF(slopes_DF, stat_func)\n",
    "\n",
    "    # this needs to be median, because at some frequencies there can be strong outliers\n",
    "    total_central_value = freq_dependent_slopes.median()\n",
    "    boot_res = bootstrap(\n",
    "        (freq_dependent_slopes.values,),\n",
    "        np.median,\n",
    "        n_resamples=1000,\n",
    "        confidence_level=0.68,\n",
    "        method=\"BCa\",\n",
    "    )\n",
    "    bounds_total_central_value = (\n",
    "        boot_res.confidence_interval.low,\n",
    "        boot_res.confidence_interval.high,\n",
    "    )\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    if labels == None:\n",
    "        glabels = [k.split(\"_\")[1] for k in slopes_DF.index.values]\n",
    "    else:\n",
    "        glabels = labels\n",
    "    ax[0].plot(\n",
    "        frequencies_MHz, slopes_DF.values.T, linestyle=\"-\", alpha=0.1\n",
    "    )  # , label=glabels)\n",
    "    ax[0].plot(\n",
    "        frequencies_MHz, slopes_DF.values.T, marker=\"o\", linestyle=\"\", markersize=3\n",
    "    )  # , label=glabels)\n",
    "\n",
    "    ax[0].plot(\n",
    "        freq_dependent_slopes.index.values, freq_dependent_slopes.values, label=stat\n",
    "    )\n",
    "    ax[0].fill_between(\n",
    "        frequencies_MHz,\n",
    "        bounds[0,],\n",
    "        bounds[1,],\n",
    "        alpha=0.3,\n",
    "        label=\"68% CI\",\n",
    "    )\n",
    "\n",
    "    ax[0].set_xlabel(\"frequency [MHz]\")\n",
    "    ax[0].set_ylabel(\"voltage \\ncalibration parameter\")\n",
    "\n",
    "    ax[0].axes.axhline(\n",
    "        total_central_value,\n",
    "        color=\"grey\",\n",
    "        lw=3,\n",
    "        label=\"Me(CP(f))={:.2f}\".format(total_central_value),\n",
    "    )\n",
    "    ax[0].axes.axhspan(\n",
    "        bounds_total_central_value[0],\n",
    "        bounds_total_central_value[1],\n",
    "        color=\"grey\",\n",
    "        alpha=0.3,\n",
    "        label=\"68% CI\",\n",
    "    )\n",
    "    ax[0].legend(fontsize=12)\n",
    "\n",
    "    ax[1].plot(frequencies_MHz, intercepts_DF.values.T, label=glabels)\n",
    "    ax[1].set_ylim(0, 5)\n",
    "    ax[1].set_xlabel(\"frequency [MHz]\")\n",
    "    ax[1].set_ylabel(\"voltage \\nnoise offset \")\n",
    "    ax[1].xaxis.set_major_locator(MultipleLocator(10))\n",
    "    ax[1].legend(fontsize=12, ncol=2)\n",
    "\n",
    "    fig.subplots_adjust(\n",
    "        left=0.2,\n",
    "        bottom=0.2,\n",
    "        wspace=0.3,\n",
    "    )\n",
    "    \n",
    "    return total_central_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ensures Plotly output works in multiple places:\n",
    "# plotly_mimetype: VS Code notebook UI\n",
    "# notebook: \"Jupyter: Export to HTML\" command in VS Code\n",
    "# See https://plotly.com/python/renderers/#multiple-renderers\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"plotly_mimetype+notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some global plot settings\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "plt.rcParams[\"legend.fontsize\"] = 14\n",
    "\n",
    "plt.rcParams[\"xtick.major.width\"] = 2\n",
    "plt.rcParams[\"ytick.major.width\"] = 2\n",
    "\n",
    "plt.rcParams[\"xtick.major.size\"] = 5\n",
    "plt.rcParams[\"ytick.major.size\"] = 5\n",
    "\n",
    "plt.rcParams[\"xtick.labelsize\"] = 14\n",
    "plt.rcParams[\"ytick.labelsize\"] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this example you need to create a mock power dataframe and simulated sidereal power dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate with \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this case the recorded is the mock dataset\n",
    "power_rec_DF = pd.read_csv(\n",
    "    # \"./mock_power_datasets/mock_power_dataset-Salla_EW_GSM16_N10000_temp30.0C_0.0additionalnoise_rounding-True.csv\",\n",
    "    \"./mock_power_datasets/mock_power_dataset-Salla_EW_GSM16_N10000_temp-10_50C_0.0additionalnoise_rounding-True.csv\",\n",
    "    index_col=0,\n",
    ")\n",
    "\n",
    "# power_rec_DF.iloc[:, :] = power_rec_DF.values\n",
    "# power_rec_DF = power_rec_DF.iloc[:, 30:80]\n",
    "power_rec_DF.columns = power_rec_DF.columns.astype(float)\n",
    "\n",
    "dir_path = \"./simulated_power_datasets/\"\n",
    "df_files = [\n",
    "    os.path.join(dir_path, i) for i in os.listdir(dir_path) if (i.endswith(\".csv\") & i.startswith('Salla'))\n",
    "]\n",
    "power_sim_DF = pd.read_csv(df_files[-3], index_col=0)\n",
    "# power_sim_DF.iloc[:, :] = power_sim_DF.values\n",
    "power_sim_DF.columns = power_sim_DF.columns.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit each band and make a plot overview\n",
    "cmapT = plt.get_cmap(\"jet\")\n",
    "bounds = np.arange(30, 83, 2)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmapT.N)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "frequencies_MHz = power_sim_DF.columns.values\n",
    "slopes = []\n",
    "intercepts = []\n",
    "for i, freq in enumerate(power_sim_DF.columns):\n",
    "    c = [freq] * power_rec_DF.index.size\n",
    "    x_arr = power_sim_DF.loc[:, freq].values\n",
    "    y_arr = power_rec_DF.loc[:, freq].values\n",
    "    cs = ax.scatter(x_arr, y_arr, s=10, c=c, norm=norm, cmap=\"jet\")\n",
    "\n",
    "    intercept, slope = robust_regression(x_arr, y_arr)\n",
    "    intercepts.append(intercept)\n",
    "    slopes.append(slope)\n",
    "    x_new = np.linspace(np.min(x_arr), np.max(x_arr), 100)\n",
    "    ax.plot(\n",
    "        x_new,\n",
    "        x_new * slope + intercept,\n",
    "        color=cmapT((freq - np.min(bounds)) * (bounds[1] - bounds[0]) / 100),\n",
    "    )\n",
    "\n",
    "intercepts = np.asarray(intercepts) ** (1 / 2)\n",
    "slopes = np.asarray(slopes) ** (1 / 2)\n",
    "\n",
    "cbar = fig.colorbar(cs, ticks=np.arange(30, 81, 4), ax=ax)\n",
    "cbar.set_label(\"Frequency [MHz]\")\n",
    "ax.set_xlabel(\"simulated power [pW]\")\n",
    "ax.set_ylabel(\"measured (mock) power [pW]\")\n",
    "fig.subplots_adjust(left=0.15, bottom=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_data = pickle.dumps(fig)\n",
    "fig2 = pickle.loads(fig_data)\n",
    "\n",
    "# modify the axis limits of the copied figure\n",
    "ax2 = fig2.axes\n",
    "ax2[0].set_ylim(14, 55)\n",
    "fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "calculate_and_plot_with_true([(df_files[-3])], power_rec_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate with all 'not true' simulated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "df_names = []\n",
    "except_this = 'Salla_GSM16'\n",
    "for f in df_files:\n",
    "    if except_this not in f:\n",
    "        df = pd.read_csv(f, index_col=0)\n",
    "        df.columns = df.columns.astype(float)\n",
    "        df_list.append(df)\n",
    "        df_names.append(Path(f).stem)\n",
    "\n",
    "concatenated_sim_df = pd.concat(df_list, keys=df_names)\n",
    "# check keys\n",
    "[key for key in concatenated_sim_df.index.levels[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes_DF, intercepts_DF = get_slope_and_intercepts_dfs(concatenated_sim_df, power_rec_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_with_CI(slopes_DF, intercepts_DF, title=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteratively apply the previous procedure to all simulated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this example you need to create a mock power dataframe and simulated sidereal power dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "def calculate_and_plot_results(df_sim_files, df_mock_files, df_true_sim_file_path):\n",
    "    print(df_sim_files, df_mock_files, df_true_sim_file_path)\n",
    "    # calculate\n",
    "    # read in all simulated datasets except the \"true\" one\n",
    "    df_list = []\n",
    "    df_names = []\n",
    "    for f in df_sim_files:\n",
    "        df = pd.read_csv(f, index_col=0)\n",
    "        df.columns = df.columns.astype(float)\n",
    "        df_list.append(df)\n",
    "        df_names.append(Path(f).stem)\n",
    "\n",
    "    concatenated_sim_df = pd.concat(df_list, keys=df_names)\n",
    "    # read-in rec dataset\n",
    "    power_rec_DF = pd.read_csv(\n",
    "        df_mock_files[0],\n",
    "        index_col=0,\n",
    "    )\n",
    "    power_rec_DF.columns = power_rec_DF.columns.astype(float)\n",
    "\n",
    "    # fitted with all others\n",
    "    slopes_DF, intercepts_DF = get_slope_and_intercepts_dfs(\n",
    "        concatenated_sim_df, power_rec_DF\n",
    "    )\n",
    "    median = plot_results_with_CI(slopes_DF, intercepts_DF, title=\"True: {}\".format(gmodel))\n",
    "    # fitted with True\n",
    "    calculate_and_plot_with_true(df_true_sim_file_path, power_rec_DF)\n",
    "\n",
    "    return slopes_DF, intercepts_DF, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_datasets_path = \"./mock_power_datasets/\"\n",
    "sim_datasets_path = \"./simulated_power_datasets/\"\n",
    "\n",
    "galactic_models = [\n",
    "    \"GSM16\",\n",
    "    \"LFSS\",\n",
    "    \"GSM08\",\n",
    "    \"Haslam\",\n",
    "    \"LFmap\",\n",
    "    \"SSM\",\n",
    "    \"GMOSS\",\n",
    "    \"ULSA\",\n",
    "]\n",
    "\n",
    "pattern = \"|\".join(galactic_models)\n",
    "\n",
    "antenna_model = \"Salla\"\n",
    "all_slopes_dict = {}\n",
    "all_intercepts_dict = {}\n",
    "medians = np.array([])\n",
    "for gmodel in galactic_models:\n",
    "    temp_galactic_models = galactic_models.copy()\n",
    "    temp_galactic_models.remove(gmodel)\n",
    "    re_string_mock = r\"{}.*{}.*N10000.*-10_50.*csv\".format(antenna_model, gmodel)\n",
    "    re_string_sim = r\"{}.*{}.*csv\".format(antenna_model, gmodel)\n",
    "\n",
    "    df_mock_files = [\n",
    "        os.path.join(mock_datasets_path, i)\n",
    "        for i in os.listdir(mock_datasets_path)\n",
    "        if re.search(re_string_mock, i)\n",
    "    ]\n",
    "\n",
    "    pattern = \"|\".join(\n",
    "        [\"^{}.*\".format(antenna_model) + s for s in temp_galactic_models]\n",
    "    )\n",
    "    df_sim_files = [\n",
    "        os.path.join(sim_datasets_path, i)\n",
    "        for i in os.listdir(sim_datasets_path)\n",
    "        if re.search(pattern, i) != None\n",
    "    ]\n",
    "\n",
    "    df_true_sim_file_path = [\n",
    "        os.path.join(sim_datasets_path, i)\n",
    "        for i in os.listdir(sim_datasets_path)\n",
    "        if re.search(re_string_sim, i)\n",
    "    ]\n",
    "    all_slopes_dict[gmodel], all_intercepts_dict[gmodel], m = calculate_and_plot_results(df_sim_files, df_mock_files, df_true_sim_file_path)\n",
    "    medians = np.append(medians, m)\n",
    "    # here should be the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_slopes_df = pd.concat(all_slopes_dict)\n",
    "all_intercepts_df = pd.concat(all_intercepts_dict)\n",
    "\n",
    "freq_dependent_slopes, bounds = bounds_from_slope_DF(all_slopes_df, np.mean)\n",
    "\n",
    "plot_results_with_CI(all_slopes_df, all_intercepts_df, title=\"All results together\", labels='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title('possible biases')\n",
    "ax.hist(medians)\n",
    "ax.set_xlabel('voltage calibration parameter')\n",
    "ax.set_ylabel('Entries')\n",
    "\n",
    "print(np.min(medians), np.max(medians))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (medians,)  # samples must be in a sequence\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "res = bootstrap(data, np.mean, confidence_level=0.9)\n",
    "bvalues = res.bootstrap_distribution\n",
    "ax[0].hist(bvalues, bins=25)\n",
    "ax[0].set_title('boostraped')\n",
    "ax[0].set_xlabel(r'$<bias>$')\n",
    "ax[0].text(0.05, 0.95, '$\\mu$={:.2f}'.format(np.mean(bvalues)), transform=ax[0].transAxes, fontsize=14,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "ax[1].set_title('boostraped')\n",
    "res = bootstrap(data, np.std, confidence_level=0.9)\n",
    "bvalues = res.bootstrap_distribution\n",
    "ax[1].hist(bvalues, bins=25)\n",
    "ax[1].set_xlabel('$\\sigma$ bias')\n",
    "ax[1].text(0.05, 0.95, '$\\mu$={:.2f}'.format(np.mean(bvalues)), transform=ax[1].transAxes, fontsize=14,\n",
    "        verticalalignment='top', bbox=props)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
