{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration - measured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radiocalibrationtoolkit import *\n",
    "from astropy.time import Time\n",
    "from astropy import units as u\n",
    "import matplotlib as mpl\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from scipy.stats import bootstrap\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter, AutoMinorLocator\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some global plot settings\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "plt.rcParams[\"legend.fontsize\"] = 14\n",
    "\n",
    "plt.rcParams[\"xtick.major.width\"] = 2\n",
    "plt.rcParams[\"ytick.major.width\"] = 2\n",
    "\n",
    "plt.rcParams[\"xtick.major.size\"] = 5\n",
    "plt.rcParams[\"ytick.major.size\"] = 5\n",
    "\n",
    "plt.rcParams[\"xtick.labelsize\"] = 14\n",
    "plt.rcParams[\"ytick.labelsize\"] = 14\n",
    "\n",
    "layout_settings = dict(\n",
    "    #title=\"<b>Measured power dataset: </b>\",\n",
    "    xaxis=dict(title=\"<b>LST</b>\", tickprefix=\"<b>\", ticksuffix=\"</b>\", dtick=2),\n",
    "    yaxis=dict(\n",
    "        title=\"<b>frequency [MHz]</b>\",\n",
    "        tickprefix=\"<b>\",\n",
    "        ticksuffix=\"</b>\",\n",
    "        range=(30, 80),\n",
    "        tick0=0,\n",
    "        dtick=10,\n",
    "        autorange=False,\n",
    "    ),\n",
    "    font=dict(\n",
    "        size=20,\n",
    "        color=\"black\",\n",
    "    ),\n",
    "    coloraxis=dict(\n",
    "        colorbar=dict(\n",
    "            tickprefix=\"<b>\",\n",
    "            ticksuffix=\"</b>\",\n",
    "            title=dict(text=\"<b>Power [pW]</b>\", side=\"right\")),\n",
    "        cmin=0,\n",
    "        cmax=24,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ensures Plotly output works in multiple places:\n",
    "# plotly_mimetype: VS Code notebook UI\n",
    "# notebook: \"Jupyter: Export to HTML\" command in VS Code\n",
    "# See https://plotly.com/python/renderers/#multiple-renderers\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"plotly_mimetype+notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some extra functions\n",
    "\n",
    "def date_filtering(df, timePeriodCut=[0, np.inf]):\n",
    "    if 'gpsTime' in df:\n",
    "        return df[(df.gpsTime > timePeriodCut[0]) & (df.gpsTime < timePeriodCut[1])].reset_index(drop=True)\n",
    "    else:\n",
    "        print(\"[ERROR] No column called 'gpsTime'\")\n",
    "\n",
    "def encode_dataframes_to_latex(mean_df, neg_error_df, pos_error_df, overal_cal_params_df):\n",
    "    # Compute the mean + poserr/-negerr values and format them with two decimal places\n",
    "    formatted_values_df = (\n",
    "        mean_df.applymap(\"${:.2f}\".format)\n",
    "        + neg_error_df.abs().applymap('_{{-{:.1f}\\%}}'.format)\n",
    "        + pos_error_df.abs().applymap('^{{+{:.1f}\\%}}$'.format)\n",
    "    )\n",
    "    formatted_values_df = formatted_values_df.sort_index(axis=1)\n",
    "    \n",
    "    df1 = overal_cal_params_df.loc[:,'mu'].to_frame().T.applymap(\"${:.2f}\".format)\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "    overal_cal_params_rel_df = (overal_cal_params_df.div(overal_cal_params_df.loc[:,'mu'].values, axis=0) - 1).abs()*100\n",
    "    df2 = overal_cal_params_rel_df.loc[:,'err_low'].to_frame().T.applymap('_{{-{:.1f}\\%}}'.format)\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "    df3 = overal_cal_params_rel_df.loc[:,'err_up'].to_frame().T.applymap('^{{+{:.1f}\\%}}$'.format)\n",
    "    df3 = df3.reset_index(drop=True)\n",
    "    formatted_values_overall_df = df1+df2+df3\n",
    "    formatted_values_overall_df = formatted_values_overall_df.sort_index(axis=1)\n",
    "    formatted_values_overall_df.index = ['overall']\n",
    "    \n",
    "    final_df = pd.concat((formatted_values_df, formatted_values_overall_df))\n",
    "    \n",
    "    # Generate the LaTeX table\n",
    "    latex_table = final_df.to_latex(\n",
    "        header=True, escape=False, column_format=\"l\"\n",
    "    )\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "def check_substring(string, substrings):\n",
    "    for substring in substrings:\n",
    "        if substring in string:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def convert_spectra2powers_and_concatenate_dfs(dir_path, timecut=[0, np.inf], channel='channel_0', exclude_list=[None]):\n",
    "\n",
    "    df_files = [\n",
    "        os.path.join(dir_path, i) for i in os.listdir(dir_path) if ((channel in i) & ~check_substring(i, exclude_list))\n",
    "    ]\n",
    "    df_list = []\n",
    "    df_names = []\n",
    "    for f in df_files:\n",
    "        print(f)\n",
    "        spectra_df = pd.read_csv(f, index_col=0)\n",
    "        spectra_df = date_filtering(spectra_df, timePeriodCut=timecut)\n",
    "        ###########################\n",
    "        info_cols_df = spectra_df.iloc[:,:6]\n",
    "        spectra_df = spectra_df.iloc[:,6:]\n",
    "        spectra_df.columns = spectra_df.columns.astype(float)\n",
    "\n",
    "        integrand_df = ((spectra_df)* (1 / (sampling_frequency_MHz*1e+6))**2).divide(\n",
    "            impedance_func(spectra_df.columns.values)\n",
    "        )\n",
    "\n",
    "        # integrate\n",
    "        rec_power_unbinned_DF = (2 / trace_time_length_sec) *integrate_spectral_density(\n",
    "            integrand_df,\n",
    "            # integrated_MHz_bands=np.linspace(0, 125, 126),\n",
    "            integrated_MHz_bands=np.linspace(30, 80, 51),\n",
    "            integrating_method='on_discontinuous_function',\n",
    "        )\n",
    "\n",
    "        rec_power_unbinned_DF = pd.concat((info_cols_df.loc[:,'lst'], rec_power_unbinned_DF), axis=1)\n",
    "\n",
    "        power_rec_DF = bin_df_rows(rec_power_unbinned_DF, binning_column='lst', bins=list(range(25)))\n",
    "        \n",
    "        power_rec_DF.index.name = 'lst'\n",
    "        power_rec_DF = power_rec_DF.drop(['lst'], axis=1) * 1e12\n",
    "                \n",
    "        ###########################\n",
    "        df_list.append(power_rec_DF)\n",
    "        df_names.append(Path(f).stem)\n",
    "\n",
    "    return pd.concat(df_list, keys=df_names)\n",
    "\n",
    "def filename2label(input_string):\n",
    "    numbers = re.findall(r'\\d+', input_string)\n",
    "    ls_number = numbers[0] if numbers else ''\n",
    "    ch_number = numbers[1] if len(numbers) >= 2 else ''\n",
    "\n",
    "    new_string = f\"LS:{ls_number} Ch:{ch_number}\"\n",
    "    return new_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## SET ORIENTATION ########\n",
    "orientation = 'EW'\n",
    "if orientation == 'EW':\n",
    "    channel = 'channel_0'\n",
    "    exclude_list = ['noexclusion']\n",
    "elif orientation == 'NS':\n",
    "    channel = 'channel_1'\n",
    "    exclude_list=[\"1733\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data conversion to power dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system parameters\n",
    "sampling_frequency_MHz = 250\n",
    "ADC2Volts = 1/2048\n",
    "N = 1024\n",
    "trace_time_length_sec = N/(sampling_frequency_MHz*1e+6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read HW response\n",
    "hw_file_path = \"./antenna_setup_files/HardwareProfileList_realistic.xml\"\n",
    "# hw_file_path = \"./antenna_setup_files/HardwareProfileList_flat.xml\"\n",
    "\n",
    "hw_dict = read_hw_file(hw_file_path, interp_args={\"fill_value\": \"extrapolate\"})\n",
    "\n",
    "# impedance function\n",
    "impedance_func = hw_dict[\"IImpedance\"][\"antenna_\"+orientation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in voltage already\n",
    "spectra_df = pd.read_csv(\n",
    "    \"/home/tomas/Documents/myRUthesis/thesis_codes/converted_f16/voltage_squared_spectra_31742_\"+channel+\".csv\", index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# startDay = Time('2021-12-29 00:00:00.000', format='iso')\n",
    "startDay = Time('2022-01-03 00:00:00.000', format='iso')\n",
    "endDay = startDay + 1*u.day\n",
    "spectra_df = date_filtering(spectra_df, [startDay.gps, endDay.gps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_cols_df = spectra_df.iloc[:,:6]\n",
    "spectra_df = spectra_df.iloc[:,6:]\n",
    "spectra_df.columns = spectra_df.columns.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrand_df = ((spectra_df)* (1 / (sampling_frequency_MHz*1e+6))**2).divide(\n",
    "    impedance_func(spectra_df.columns.values)\n",
    ")\n",
    "\n",
    "# integrate\n",
    "rec_power_unbinned_DF = (2 / trace_time_length_sec) *integrate_spectral_density(\n",
    "    integrand_df,\n",
    "    # integrated_MHz_bands=np.linspace(0, 125, 126),\n",
    "    integrated_MHz_bands=np.linspace(30, 80, 51),\n",
    "    integrating_method='on_discontinuous_function',\n",
    ")\n",
    "rec_power_unbinned_DF = pd.concat((info_cols_df.loc[:,'lst'], rec_power_unbinned_DF), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_rec_DF = bin_df_rows(rec_power_unbinned_DF, binning_column='lst', bins=list(range(25)))\n",
    "power_rec_DF.index.name = 'lst'\n",
    "power_rec_DF = power_rec_DF.drop(['lst'], axis=1) * 1e12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_rec_example_DF = power_rec_DF.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(power_rec_DF.T, width=600, aspect=\"cube\", color_continuous_scale=\"jet\")\n",
    "fig.update_layout(**layout_settings)\n",
    "fig.update_layout(\n",
    "    title=\"<b>Measured power dataset: </b>\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of simulated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antenna_type = 'Salla_'+orientation\n",
    "\n",
    "dir_path = \"./simulated_power_datasets/\"\n",
    "concatenated_sim_df = concatenate_simulated_dfs(dir_path, antenna_type)\n",
    "\n",
    "# check keys\n",
    "[key for key in concatenated_sim_df.index.levels[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky_model = \"GSM08\"\n",
    "\n",
    "fig = px.imshow(\n",
    "    concatenated_sim_df.xs(\"Salla_\" + orientation + \"_\" + sky_model).T,\n",
    "    width=600,\n",
    "    aspect=\"cube\",\n",
    "    color_continuous_scale=\"jet\",\n",
    ")\n",
    "fig.update_layout(**layout_settings)\n",
    "fig.update_layout(\n",
    "    title=\"<b>Simulated power dataset: \" + sky_model + \" \" + orientation + \"</b>\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes_DF, intercepts_DF = get_fitted_voltage_cal_params_and_noise_offsets_from_concat_sim_dfs(concatenated_sim_df, power_rec_DF)\n",
    "get_and_plot_calibration_results(slopes_DF, intercepts_DF, title=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_sim_DF = concatenated_sim_df.loc['Salla_'+orientation + \"_\" + sky_model]\n",
    "\n",
    "fig = px.imshow(\n",
    "    power_sim_DF.add(\n",
    "        intercepts_DF.loc[\"Salla_\" + orientation + \"_\" + sky_model].values, axis=1\n",
    "    ).T,\n",
    "    width=600,\n",
    "    aspect=\"cube\",\n",
    "    color_continuous_scale=\"jet\",\n",
    ")\n",
    "fig.update_layout(**layout_settings)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"<b>Simulated dataset + fitted noise</b>\",\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = px.imshow(\n",
    "    power_rec_DF.sub(\n",
    "        intercepts_DF.loc[\"Salla_\" + orientation + \"_\" + sky_model].values, axis=1\n",
    "    ).T,\n",
    "    width=600,\n",
    "    aspect=\"cube\",\n",
    "    color_continuous_scale=\"jet\",\n",
    ")\n",
    "fig.update_layout(**layout_settings)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"<b>Measured dataset - fitted noise</b>\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of measured datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"/home/tomas/Documents/myRUthesis/thesis_codes/converted_f16/\"\n",
    "#\n",
    "if orientation == 'EW':\n",
    "    channel = 'channel_0'\n",
    "    exclude_list = ['noexclusion']\n",
    "elif orientation == 'NS':\n",
    "    channel = 'channel_1'\n",
    "    exclude_list=[\"1733\"]\n",
    "\n",
    "concatenated_rec_df = convert_spectra2powers_and_concatenate_dfs(dir_path, timecut=[0, np.inf], channel=channel, exclude_list=exclude_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_rec_df.index.levels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overal_cal_params_dict = {}\n",
    "# labels = []\n",
    "for key in concatenated_rec_df.index.levels[0]:\n",
    "    print('**************************')\n",
    "    print(filename2label(key))\n",
    "    power_rec_DF = concatenated_rec_df.xs(key)\n",
    "    slopes_DF, intercepts_DF = get_fitted_voltage_cal_params_and_noise_offsets_from_concat_sim_dfs(concatenated_sim_df, power_rec_DF)\n",
    "    stats = get_and_plot_calibration_results(slopes_DF, intercepts_DF, title=filename2label(key))\n",
    "    # fig, ax = plt.subplots()\n",
    "    # _, _, stats = create_KDE_plot(\n",
    "    #     truncate_data(dropnans(slopes_DF.values.flatten()), 5, 95), bins=np.linspace(0., 2, 3000)\n",
    "    # )\n",
    "    # labels.append(filename2label(key))\n",
    "    overal_cal_params_dict[filename2label(key)] = stats\n",
    "    print('**************************')\n",
    "\n",
    "    # all_stats.append(stats)\n",
    "\n",
    "overal_cal_params_df = pd.DataFrame(overal_cal_params_dict).T\n",
    "overal_cal_params_df.columns = ['mu', 'err_low', 'err_up']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super concating: time and stations\n",
    "# we have 12 full days (until 9th of January)\n",
    "startDay = Time(\"2021-12-29 00:00:00.000\", format=\"iso\")\n",
    "dir_path = \"/home/tomas/Documents/myRUthesis/thesis_codes/converted_f16/\"\n",
    "\n",
    "concat_dfs_per_day_dict = {}\n",
    "for i in range(12):\n",
    "    print(startDay)\n",
    "    endDay = startDay + 1 * u.day\n",
    "    concatenated_rec_df = convert_spectra2powers_and_concatenate_dfs(\n",
    "        dir_path, timecut=[startDay.gps, endDay.gps], channel=channel, exclude_list=exclude_list\n",
    "    )\n",
    "    concat_dfs_per_day_dict[startDay.iso[:10]] = concatenated_rec_df\n",
    "    startDay += 1 * u.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_rec_df.index.levels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrating\n",
    "\n",
    "concat_dfs_per_day_dict['2021-12-30']\n",
    "\n",
    "nested_dict = lambda: collections.defaultdict(nested_dict)\n",
    "means_dict = nested_dict()\n",
    "lowererr_dict = nested_dict()\n",
    "uppererr_dict = nested_dict()\n",
    "\n",
    "for date in concat_dfs_per_day_dict.keys():\n",
    "    print(date)\n",
    "\n",
    "    all_stats = []\n",
    "    labels = []\n",
    "    concatenated_rec_df = concat_dfs_per_day_dict[date]\n",
    "    for key in concatenated_rec_df.index.levels[0]:\n",
    "        print('*******************************')\n",
    "        print(filename2label(key))\n",
    "        power_rec_DF = concatenated_rec_df.xs(key)\n",
    "        slopes_DF, intercepts_DF = get_fitted_voltage_cal_params_and_noise_offsets_from_concat_sim_dfs(concatenated_sim_df, power_rec_DF)\n",
    "        stats = get_frequency_independent_calibration_param(slopes_DF)\n",
    "        # fig, ax = plt.subplots()\n",
    "        # _, _, stats = create_KDE_plot(\n",
    "        #     truncate_data(dropnans(slopes_DF.values.flatten()), 5, 95), bins=np.linspace(0., 2, 3000)\n",
    "        # )\n",
    "        # stats = plot_results_with_CI(slopes_DF, intercepts_DF, title=filename2label(key))\n",
    "        labels.append(filename2label(key))\n",
    "        all_stats.append(stats)\n",
    "        means_dict[date][filename2label(key)] = stats[2]\n",
    "        lowererr_dict[date][filename2label(key)] = stats[0]\n",
    "        uppererr_dict[date][filename2label(key)] = stats[1]\n",
    "        print('*******************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_df = pd.DataFrame(means_dict)\n",
    "lowererr_df = pd.DataFrame(lowererr_dict)\n",
    "uppererr_df = pd.DataFrame(uppererr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_cycle = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "fig, ax = plt.subplots()\n",
    "xdate = [\n",
    "    datetime.datetime.strptime(date_str, \"%Y-%m-%d\").date()\n",
    "    for date_str in means_df.columns.values\n",
    "]\n",
    "for i, row in enumerate(means_df.index):\n",
    "    color = color_cycle[i % len(color_cycle)]\n",
    "    y = means_df.loc[row, :].values\n",
    "    yerr_low = lowererr_df.loc[row, :].values\n",
    "    yerr_up = uppererr_df.loc[row, :].values\n",
    "\n",
    "    plt.gca().set_prop_cycle(plt.rcParams[\"axes.prop_cycle\"])\n",
    "    ax.errorbar(\n",
    "        xdate,\n",
    "        y,\n",
    "        yerr=[abs(yerr_low - y), abs(yerr_up - y)],\n",
    "        label=row,\n",
    "        color=color,\n",
    "        marker=\"o\",\n",
    "        lw=0.5,\n",
    "    )\n",
    "    ax.axes.axhline(overal_cal_params_df.loc[row, \"mu\"], color=color)\n",
    "\n",
    "ax.tick_params(axis=\"x\", rotation=45)\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
    "\n",
    "mu_total, err_low_total, err_up_total = overal_cal_params_df.mean()\n",
    "ax.axes.axhline(\n",
    "    mu_total,\n",
    "    color=\"k\",\n",
    "    lw=3,\n",
    "    label=r\"$C_{{\\mathrm{{overall}}}}={:.2f}_{{-{:.1f}\\%}}^{{+{:.1f}\\%}}$\".format(\n",
    "        mu_total,\n",
    "        abs(err_low_total / mu_total - 1)*100,\n",
    "        abs(err_up_total / mu_total - 1)*100,\n",
    "    ),\n",
    ")\n",
    "ax.axes.axhspan(err_low_total, err_up_total, color=\"k\", alpha=0.1)\n",
    "\n",
    "ax.set_ylim(0.8, 1.25)\n",
    "ax.set_ylabel(\"voltage calibration parameter\")\n",
    "ax.legend(loc=\"lower left\", bbox_to_anchor=(1, 0.42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overal_cal_params_df.columns = ['mu', 'err_low', 'err_up']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltable = encode_dataframes_to_latex(\n",
    "    means_df.T,\n",
    "    np.abs(lowererr_df.T / means_df.T.values - 1) * 100,\n",
    "    np.abs(uppererr_df.T / means_df.T.values - 1) * 100,\n",
    "    overal_cal_params_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(means_df.T.sort_index(axis=1))\n",
    "display(overal_cal_params_df.T)\n",
    "\n",
    "print(ltable)\n",
    "display('Universal channel calibration parameter:')\n",
    "display(overal_cal_params_df.mean()[['mu']])\n",
    "display('Its error in %:')\n",
    "display((overal_cal_params_df.mean()/overal_cal_params_df.mean().mu - 1)[['err_low', 'err_up']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data type precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_f16_df = pd.read_csv(\n",
    "    \"/home/tomas/Documents/myRUthesis/thesis_codes/converted_f16/voltage_squared_spectra_30056_channel_0.csv\", index_col=0\n",
    ")\n",
    "spectra_full_df = pd.read_csv(\n",
    "    \"/home/tomas/Documents/myRUthesis/thesis_codes/converted_full_precision/voltage_squared_spectra_30056_channel_0.csv\", index_col=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"frequency [MHz]\")\n",
    "ax.set_ylabel(\n",
    "    r\"$\\frac{{\\mathrm{{power \\: from \\: 64 \\: int}}}}{{{}\\: \\mathrm{{power from \\:bit \\:float   }}}} - 1$\".format(\n",
    "        16\n",
    "    )\n",
    ")\n",
    "ax.plot(\n",
    "    spectra_full_df.columns[6:].values.astype(float),\n",
    "    (spectra_full_df / spectra_f16_df.values).iloc[50, 6:].values - 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*[Time(i, format='gps').iso+'\\n' for i in spectra_f16_df.gpsTime])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes_DF, intercepts_DF = get_fitted_voltage_cal_params_and_noise_offsets_from_concat_sim_dfs(concatenated_sim_df, power_rec_example_DF)\n",
    "get_and_plot_calibration_results(slopes_DF, intercepts_DF, title=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first create this dataset of results\n",
    "overallNoiseFitResultDF = pd.concat((slopes_DF.mean(axis=0), intercepts_DF.mean(axis=0)), axis=1)\n",
    "overallNoiseFitResultDF.columns=['S', 'Nf']\n",
    "# and average simulated datasets\n",
    "power_sim_avr_df = concatenated_sim_df.groupby(level=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "def _Baseline_als(y, lam=None, p=None, niter=10):\n",
    "    L = len(y)\n",
    "    D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(L, L - 2))\n",
    "    w = np.ones(L)\n",
    "    for i in range(niter):\n",
    "        W = sparse.spdiags(w, 0, L, L)\n",
    "        Z = W + lam * D.dot(D.transpose())\n",
    "        z = spsolve(Z, w * y)\n",
    "        w = p * (y > z) + (1 - p) * (y < z)\n",
    "    return z\n",
    "\n",
    "def extract_baseline(dataset):\n",
    "    newDataset = dataset.copy(deep=True)\n",
    "    for i in range(dataset.index.size):\n",
    "        arr = dataset.iloc[i, :].values\n",
    "        newDataset.iloc[i, :] = _Baseline_als(\n",
    "            arr, lam=500, p=0.1, niter=100\n",
    "        )\n",
    "    #                 self._newDataset.iloc[i,:] = baseline_als2(self._dataset.iloc[i,:].values, lam=100, lam1=0.01, p=0.1, niter=100)\n",
    "    return newDataset\n",
    "\n",
    "power_rec_baseline_DF = extract_baseline(power_rec_DF/ overallNoiseFitResultDF.S.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shared_subfigures(\n",
    "    rows, cols, subfig_width, subfig_height, hspace=0.2, wspace=0.2\n",
    "):\n",
    "    fig, axes = plt.subplots(\n",
    "        rows,\n",
    "        cols,\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "        figsize=(subfig_width * cols, subfig_height * rows),\n",
    "    )\n",
    "\n",
    "    if rows == 1 & cols != 1:\n",
    "        axes = axes.reshape(1, cols)\n",
    "    elif rows == 1 & cols == 1:\n",
    "        axes = np.array(axes).reshape(1, 1)\n",
    "\n",
    "    plt.subplots_adjust(wspace=wspace, hspace=hspace)\n",
    "\n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "# Figure settings:\n",
    "rows = 5\n",
    "cols = 5\n",
    "subfig_width = 4\n",
    "subfig_height = 4\n",
    "h_space = 0.1\n",
    "v_space = 0.1\n",
    "legend = True\n",
    "\n",
    "# input\n",
    "measuredDFRaw = power_rec_example_DF / overallNoiseFitResultDF.S.values\n",
    "measuredDFRaw.index = np.asarray(measuredDFRaw.index.values) + 0.5\n",
    "galaxySimulationDF = power_sim_avr_df\n",
    "systemNoiseFitResultDF = overallNoiseFitResultDF\n",
    "# lst=[5.5, 18.5]\n",
    "lst = np.arange(24) + 0.5\n",
    "\n",
    "# make\n",
    "fig, axes = create_shared_subfigures(\n",
    "    rows, cols, subfig_width, subfig_height, hspace=h_space, wspace=v_space\n",
    ")\n",
    "\n",
    "axes[0, 0].set_xlim(28, 82)\n",
    "axes[0, 0].set_ylim(0, 40)\n",
    "\n",
    "# Add x-axis labels only to the bottom row subfigures\n",
    "for c in range(cols):\n",
    "    axes[rows - 1, c].set_xlabel(\"frequency [MHz]\")\n",
    "\n",
    "# Add y-axis labels only to the leftmost column subfigures\n",
    "for r in range(rows):\n",
    "    axes[r, 0].set_ylabel(\"power [pW]\")\n",
    "\n",
    "i = 0\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "        axes[r, c].plot([1, 2, 3, 4, 5], [r + c * 2] * 5)\n",
    "\n",
    "        # try:\n",
    "        # x-axis measured RAW\n",
    "        frequencyRaw = measuredDFRaw.columns.values.astype(float)\n",
    "        measuredNoiseRaw = measuredDFRaw.loc[lst[i], :].values\n",
    "        # plot measured data\n",
    "        axes[r, c].plot(\n",
    "            frequencyRaw,\n",
    "            measuredNoiseRaw,\n",
    "            color=\"k\",\n",
    "            linewidth=2,\n",
    "            label=\"cal. measured signal\",\n",
    "        )\n",
    "        # except Exception as e:\n",
    "        #     if i == 0:\n",
    "        #         print('[INFO] No \"measuredNoiseRaw\".')\n",
    "        #     pass\n",
    "\n",
    "        try:\n",
    "            # x-axis measured, baseline\n",
    "            frequencyBaseline = measuredDFBaseline.columns.values.astype(float)\n",
    "            measuredNoiseBaseline = measuredDFBaseline.loc[lst[i], :].values\n",
    "            # plot measured data\n",
    "            axes[r, c].plot(\n",
    "                frequencyBaseline,\n",
    "                measuredNoiseBaseline,\n",
    "                color=\"g\",\n",
    "                linewidth=2,\n",
    "                label=\"tot.signa(measured)\\n-Baseline\",\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # print(f\"An error occurred: {e}\")\n",
    "            # if i == 0:\n",
    "            #     print('[INFO] No \"measuredNoiseBaseline\".')\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            # x-axis measured, baseline\n",
    "            frequencyGalaxySimulation = galaxySimulationDF.columns.values.astype(float)\n",
    "            galaxySignal = galaxySimulationDF.loc[lst[i], :].values\n",
    "            # plot measured data\n",
    "            axes[r, c].bar(\n",
    "                frequencyGalaxySimulation,\n",
    "                galaxySignal,\n",
    "                alpha=1,\n",
    "                color=\"orange\",\n",
    "                label=\"galactic signal\",\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            if i == 0:\n",
    "                print('[INFO] No \"galaxySimulationDF\".')\n",
    "            pass\n",
    "\n",
    "        axes[r, c].bar(\n",
    "            frequencyGalaxySimulation,\n",
    "            overallNoiseFitResultDF.Nf.values,\n",
    "            bottom=galaxySignal,\n",
    "            color=\"b\",\n",
    "            label=\"thermal + external noise\",\n",
    "            alpha=0.5,\n",
    "        )\n",
    "\n",
    "        textstr = \"LST: \" + str(lst[i]) + \" hour\"\n",
    "        props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "        axes[r, c].text(\n",
    "            0.25,\n",
    "            0.97,\n",
    "            textstr,\n",
    "            transform=axes[r, c].transAxes,\n",
    "            fontsize=14,\n",
    "            verticalalignment=\"top\",\n",
    "            bbox=props,\n",
    "        )\n",
    "\n",
    "        i += 1\n",
    "        if i == len(lst):\n",
    "            break\n",
    "\n",
    "if legend:\n",
    "    axes[-1, -2].legend(fontsize=12)\n",
    "\n",
    "    label_params = axes[-1, -2].get_legend_handles_labels()\n",
    "\n",
    "    axes[-1, -1].axis(False)\n",
    "    axes[-1, -1].legend(\n",
    "        *label_params,\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(-0.1, 1.02),\n",
    "        prop={\"size\": 14},\n",
    "        fontsize=16,\n",
    "    )\n",
    "\n",
    "    axes[-1, -2].get_legend().remove()\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    axes[-1, -1].xaxis.set_major_locator(MultipleLocator(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of calibration methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_calibration_methods(df1, df2, col_start=0, pick_every=4, method='band2band', title=True):\n",
    "\n",
    "    # fit each band separately but we a common slope\n",
    "    x_data_set = df1.iloc[:,col_start:].iloc[:,pick_every::].T.values\n",
    "    y_data_set = df2.iloc[:,col_start:].iloc[:,pick_every::].T.values\n",
    "\n",
    "    # Initial guesses for the common slope and individual intercepts\n",
    "    initial_params = [1.0] + [0.0] * len(x_data_set)  # [common slope, intercept1, intercept2, ...]\n",
    "\n",
    "    def linear_model(params, x):\n",
    "        slope = params[0]\n",
    "        intercepts = params[1:]\n",
    "        return [slope * x[i] + intercepts[i] for i in range(len(x))]\n",
    "\n",
    "    # Define the objective function to minimize (sum of squared residuals)\n",
    "    def objective(params):\n",
    "        y_pred = linear_model(params, x_data_set)\n",
    "        residuals = np.concatenate([(y - y_pred[i]) for i, y in enumerate(y_data_set)])\n",
    "        return np.sum(residuals**2)\n",
    "\n",
    "    # Perform the minimization\n",
    "    result = minimize(objective, initial_params, method='Powell')\n",
    "\n",
    "    # Extract the optimized common slope and individual intercepts\n",
    "    common_slope = result.x[0]\n",
    "    intercepts = result.x[1:]\n",
    "\n",
    "    # print(\"Common Slope:\", common_slope)\n",
    "    # print(\"Intercepts:\", intercepts)\n",
    "\n",
    "    # Discretize 'jet' colormap\n",
    "    cmap = plt.get_cmap(\"jet\", df1.shape[1])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,8))\n",
    "\n",
    "    # Set the minimum and maximum values for the colorbar\n",
    "    vmin = 30  # Replace with your desired minimum value\n",
    "    vmax = 80  # Replace with your desired maximum value\n",
    "    norm = plt.Normalize(vmin, vmax)\n",
    "\n",
    "    # Create a scatter plot for each pair of columns\n",
    "    for i, f in enumerate(df1.columns[col_start:][pick_every::]):\n",
    "        im = ax.scatter(\n",
    "            df1.loc[:, f].values,\n",
    "            df2.loc[:, f].values,\n",
    "            c=np.ones(df1.index.size) * float(f),\n",
    "            cmap=cmap,\n",
    "            norm=norm,\n",
    "            s=10\n",
    "        )\n",
    "        x  =  df1.loc[:, f].values\n",
    "        y  =  df2.loc[:, f].values\n",
    "        if method == 'band2band':\n",
    "            # each band fitted totally independently\n",
    "            q, k = robust_regression(x, y)\n",
    "            ax.plot(x, k * x + q, color=cmap(norm(f)))\n",
    "        elif method == 'band2band_common_slope':\n",
    "            # each band separately but with a common slope\n",
    "            y_fit = common_slope * x + intercepts[i]\n",
    "            ax.plot(x, y_fit, color=cmap(norm(f)))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    if method == 'all-data-fit':\n",
    "        # one fit across all bands\n",
    "        x_mean = df1.values.flatten()\n",
    "        y_mean = df2.values.flatten()\n",
    "        q_mean, k_mean = robust_regression(x_mean, y_mean)\n",
    "        ax.plot(x_mean[x_mean>2.2], k_mean * x_mean[x_mean>2.2] + q_mean, color='black', linestyle='-', lw=5)\n",
    "\n",
    "    cbar = plt.colorbar(im, ax=ax, orientation=\"vertical\", label=\"frequency [MHz]\")\n",
    "\n",
    "    ax.set_ylim(10, 27)\n",
    "    ax.set_xlim(2, 13)\n",
    "\n",
    "    ax.set_xlabel(\"predicted power [pW]\")\n",
    "    ax.set_ylabel(\"measured power [pW]\")\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(\"Calibration Method:\\n{}\".format(method))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some global plot settings\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.rcParams[\"legend.fontsize\"] = 14\n",
    "\n",
    "plt.rcParams[\"xtick.major.width\"] = 3\n",
    "plt.rcParams[\"ytick.major.width\"] = 3\n",
    "\n",
    "plt.rcParams[\"xtick.major.size\"] = 6\n",
    "plt.rcParams[\"ytick.major.size\"] = 6\n",
    "\n",
    "plt.rcParams[\"xtick.labelsize\"] = 16\n",
    "plt.rcParams[\"ytick.labelsize\"] = 16\n",
    "\n",
    "df2 = power_rec_example_DF\n",
    "df1 = concatenated_sim_df.loc[\"Salla_EW_LFmap\"]\n",
    "\n",
    "col_start = 0\n",
    "pick_every = 4\n",
    "\n",
    "show_calibration_methods(df1, df2, col_start=0, pick_every=4, method='all-data-fit')\n",
    "show_calibration_methods(df1, df2, col_start=0, pick_every=4, method='band2band_common_slope')\n",
    "show_calibration_methods(df1, df2, col_start=0, pick_every=4, method='band2band')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
